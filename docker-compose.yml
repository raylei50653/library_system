services:
  db:
    image: postgres:16
    container_name: library_db
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-library_db}
      POSTGRES_USER: ${POSTGRES_USER:-ray}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-ray123456}
      PGDATA: /var/lib/postgresql/data
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB -h 127.0.0.1 -p 5432"]
      interval: 2s
      timeout: 2s
      retries: 15
      start_period: 5s

  ollama:
    image: ollama/ollama:0.12.5
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=24h
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ollama:/root/.ollama
    # ðŸ”§ åˆªæŽ‰å°å¤–æ˜ å°„ï¼Œé¿å… 11434 è¡çª
    # ports:
    #   - "11434:11434"
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 5s
      timeout: 5s
      retries: 60
      start_period: 15s
    entrypoint:
      - /bin/sh
      - -c
      - |
          set -eu
          ollama serve &

          until ollama list >/dev/null 2>&1; do
            echo "Waiting for Ollama server..."
            sleep 2
          done
          
          ollama pull qwen3:8b || true
          printf 'hi' | ollama run qwen3:8b >/dev/null 2>&1 || true
          wait
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities:
                - gpu


  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: library_backend
    env_file:
      - ./backend/.env
    environment:
      DATABASE_URL: postgresql://ray:ray123456@db:5432/library_db
      DJANGO_SECRET_KEY: ${DJANGO_SECRET_KEY:-dev-secret}
      DEBUG: "1"
      ALLOWED_HOSTS: "127.0.0.1,localhost"
      DB_HOST: db
      DB_PORT: "5432"
      OLLAMA_URL: ${OLLAMA_URL:-http://ollama:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-qwen3:8b}
      INIT_OLLAMA_MODEL: ${INIT_OLLAMA_MODEL:-qwen3:8b}
    depends_on:
      db:
        condition: service_healthy
      ollama:
        condition: service_healthy
    ports:
      - "8000:8000"
    command: ["/app/entrypoint.sh"]
    volumes:
      - ./backend:/app:cached

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: library_frontend
    env_file:
      - ./frontend/.env
    environment:
      CHOKIDAR_USEPOLLING: "1"
      VITE_PORT: ${VITE_PORT:-5173}
    depends_on:
      backend:
        condition: service_started
    ports:
      - "${VITE_PORT:-5173}:${VITE_PORT:-5173}"
    volumes:
      - ./frontend:/app
      - frontend_node_modules:/app/node_modules
    command: ["sh", "/app/entrypoint.sh"]

volumes:
  pgdata:
  ollama:
  frontend_node_modules:
